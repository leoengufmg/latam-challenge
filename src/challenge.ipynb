{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup.py -> \n",
    "\n",
    "# Constant values \n",
    "bucket_name = 'gcp_latam_twitter'\n",
    "folder_name = 'raw'\n",
    "zip_file_name = 'tweets.json.zip'\n",
    "file_id = '1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis'  # ID de ejemplo del archivo de Google Drive\n",
    "gcloud_url = f\"gs://{bucket_name}/{folder_name}/\"\n",
    "start_time = str(time.time())\n",
    "\n",
    "# Notebook time measure (consider using a timer library for better accuracy)\n",
    "start_time = str(time.time())\n",
    "\n",
    "\n",
    "# Local file paths (consider user input/environment variables for flexibility)\n",
    "drive_mount_point = '/content/drive/MyDrive'\n",
    "source_path = 'leonardora/de/latam-challenge/'\n",
    "\n",
    "# Google Cloud project and dataset information (consider environment variables for better management)\n",
    "project_id = \"hip-rain-441704-n7\"\n",
    "project_name = \"desafio-latam-leonardora\"\n",
    "dataset = \"tweets_dataset\"\n",
    "table =\"tweets\"\n",
    "\n",
    "# Logging\n",
    "logging_level = str(logging.DEBUG)\n",
    "logging.basicConfig(level=int(logging_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test.py -> \n",
    "from google.colab import drive\n",
    "import os\n",
    "import logging\n",
    "import subprocess\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "drive_mount_point = '/content/drive/MyDrive'\n",
    "source_path = 'leonardora/de/latam-challenge/'\n",
    "target_dir = os.path.join(drive_mount_point, source_path)\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "    print(f\"Directorio creado: {target_dir}\")\n",
    "else:\n",
    "    print(f\"Directorio existente: {target_dir}\")\n",
    "\n",
    "os.chdir(target_dir)\n",
    "print(f\"Directorio actual: {os.getcwd()}\")\n",
    "\n",
    "if os.path.exists(os.path.join(target_dir, \".git\")):\n",
    "    print(\"Repositorio ya existe. Haciendo pull de los Ãºltimos cambios...\")\n",
    "    !git checkout develop\n",
    "    !git pull origin develop\n",
    "else:\n",
    "    repo_url = \"https://github.com/leoengufmg/latam-challenge.git\"  # Reemplaza con la URL de tu repositorio\n",
    "    print(\"Clonando el repositorio...\")\n",
    "    !git clone {repo_url} .\n",
    "\n",
    "    !git checkout develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ->\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function.py -> setup bucket\n",
    "def create_bucket(bucket_name: str, project_id: str, location: str = \"southamerica-west1\") -> storage.Bucket:\n",
    "    \"\"\"Create a new bucket in Google Cloud Storage.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The unique name of the bucket to create.\n",
    "        project_id (str): The ID of the Google Cloud project.\n",
    "        location (str): The location where the bucket will be created (default is \"southamerica-west1\").\n",
    "\n",
    "    Returns:\n",
    "        storage.Bucket: The created bucket object.\n",
    "    \"\"\"\n",
    "    # Inicializar el cliente de Google Cloud Storage con el ID de proyecto\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    \n",
    "    # Crear el bucket\n",
    "    try:\n",
    "        bucket = storage_client.create_bucket(bucket_name, location=location)\n",
    "        print(f\"Bucket {bucket.name} created in {location}.\")\n",
    "        return bucket\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bucket: {e}\")\n",
    "        raise\n",
    "\n",
    "new_bucket = create_bucket(bucket_name, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions.py -> \n",
    "import importlib.util\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_requirements(requirements_path: str = \"./requirements.txt\") -> bool:\n",
    "    \"\"\"\n",
    "    Installs libraries listed in the requirements file if they are not already installed.\n",
    "\n",
    "    Args:\n",
    "        requirements_path (str): Path to the requirements.txt file. Defaults to \"./requirements.txt\".\n",
    "\n",
    "    Returns:\n",
    "        bool: True if installation is successful or libraries are already installed, False if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(requirements_path, 'r') as file:\n",
    "            requirements = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "        for requirement in requirements:\n",
    "            print(f\"Installing {requirement}...\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", requirement], check=True)\n",
    "            print(f\"{requirement} installed successfully.\")\n",
    "\n",
    "        print(\"All required libraries were installed successfully.\")\n",
    "        return True\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error installing libraries: {e}\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Requirements file not found at: {requirements_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test -> installing requirements\n",
    "if install_requirements():\n",
    "    print(\"Procediendo a descargar datos...\")\n",
    "else:\n",
    "    print(\"Error al instalar los requisitos. Abortando acciones adicionales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions.py -> \n",
    "import io\n",
    "import logging\n",
    "from google.colab import auth\n",
    "from google.colab import drive\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.cloud import storage\n",
    "from typing import Any\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def authenticate_google_drive() -> None:\n",
    "    \"\"\"Authenticate the user with Google Drive.\"\"\"\n",
    "    auth.authenticate_user()\n",
    "\n",
    "def mount_google_drive(mount_point: str = '/content/drive') -> None:\n",
    "    \"\"\"Mounts Google Drive to a specified mount point.\"\"\"\n",
    "    drive.mount(mount_point, force_remount=True)\n",
    "\n",
    "def download_file_from_drive(drive_service: Any, file_id: str) -> io.BytesIO:\n",
    "    \"\"\"Downloads a file from Google Drive and returns it as a BytesIO object.\"\"\"\n",
    "    downloaded = io.BytesIO()\n",
    "    try:\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        downloader = MediaIoBaseDownload(downloaded, request)\n",
    "        \n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f'Downloading {int(status.progress() * 100)}%')\n",
    "        \n",
    "        downloaded.seek(0)\n",
    "        return downloaded\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading file: {e}\")\n",
    "        raise\n",
    "\n",
    "def upload_drive_file_to_cloud_storage(bucket: storage.Bucket, folder_name: str, file_data: io.BytesIO, file_name: str) -> storage.Blob:\n",
    "    \"\"\"Uploads a file to Google Cloud Storage.\"\"\"\n",
    "    blob = bucket.blob(f\"{folder_name}/{file_name}\")\n",
    "    file_data.seek(0)  # Resetea el puntero del archivo\n",
    "    blob.upload_from_file(file_data)\n",
    "    return blob\n",
    "\n",
    "downloaded: io.BytesIO = io.BytesIO()\n",
    "\n",
    "try:\n",
    "    authenticate_google_drive()\n",
    "    mount_google_drive()\n",
    "    drive_service: Any = build('drive', 'v3')\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    downloaded = download_file_from_drive(drive_service, file_id)\n",
    "\n",
    "    if downloaded.getbuffer().nbytes == 0:\n",
    "        logging.info(\"Skipping upload as the file is empty.\")\n",
    "    else:\n",
    "        uploaded_blob = upload_drive_file_to_cloud_storage(bucket, folder_name, downloaded, zip_file_name)\n",
    "        \n",
    "        if uploaded_blob.content_type == 'application/zip':\n",
    "            logging.info(f\"File {zip_file_name} uploaded as a ZIP file.\")\n",
    "\n",
    "    logging.info(\"File transfer successful!\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    downloaded.close()\n",
    "    print(\"File transfer process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
